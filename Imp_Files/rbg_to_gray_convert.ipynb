{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e1c674d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "# Load the NPZ file\n",
    "train_data = np.load(r'D:\\Project\\AFB\\carto_mix_256_final.npz')\n",
    "x_train = train_data['arr_0']  # Assuming 'images' is the key for image data\n",
    "y_train = train_data['arr_1']  # Assuming 'labels' is the key for label data\n",
    "print(x_train.shape)\n",
    "# Convert images from RGB to Grayscale\n",
    "gray_images_x_train = []\n",
    "for img in x_train:\n",
    "    gray_img = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "    gray_images_x_train.append(gray_img)\n",
    "\n",
    "# Convert the list to a numpy array\n",
    "gray_images_x_train = np.array(gray_images_x_train)\n",
    "\n",
    "# Save the grayscale images and labels back into a new NPZ file\n",
    "#np.savez('new_one_carto_mix_256_final.npz', images=gray_images, labels=labels)\n",
    "print(gray_images_x_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdadca95",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = np.load(r'D:\\Project\\AFB\\carto_mix_256_test.npz')\n",
    "x_test = test_data['arr_0']\n",
    "y_test = test_data['arr_1']\n",
    "\n",
    "gray_images_x_test = []\n",
    "for img in x_test:\n",
    "    gray_img = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "    gray_images_x_test.append(gray_img)\n",
    "\n",
    "# Convert the list to a numpy array\n",
    "gray_images_x_test = np.array(gray_images_x_test)\n",
    "print(gray_images_x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2787bfc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import imgaug.augmenters as iaa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eb84686",
   "metadata": {},
   "outputs": [],
   "source": [
    "vflip = iaa.Flipud(1.0)\n",
    "hflip = iaa.Fliplr(1.0)\n",
    "rotate90 = iaa.Affine(rotate=90)\n",
    "rotate180 = iaa.Affine(rotate=180)\n",
    "rotate270 = iaa.Affine(rotate=270)\n",
    "rotate360 = iaa.Affine(rotate=360)\n",
    "transpose = iaa.Sequential([iaa.Affine(rotate=90), iaa.Flipud(1.0)])\n",
    "shift_scale_rotate = iaa.Affine(translate_percent={\"x\": (-0.1, 0.1), \"y\": (-0.1, 0.1)}, scale=(0.8, 1.2), rotate=(-45, 45))\n",
    "\n",
    "# Lists to store augmented images and labels\n",
    "vflip_images, vflip_labels = [], []\n",
    "hflip_images, hflip_labels = [], []\n",
    "tp_images, tp_labels = [], []\n",
    "ssr_images, ssr_labels = [], []\n",
    "t90_images, t90_labels = [], []\n",
    "t180_images, t180_labels = [], []\n",
    "t270_images, t270_labels = [], []\n",
    "t360_images, t360_labels = [], []\n",
    "\n",
    "# Function to apply augmentation\n",
    "def augment_data(augmenter, images, labels):\n",
    "    aug_images, aug_labels = [], []\n",
    "    for img, lbl in zip(images, labels):\n",
    "        aug_img = augmenter(image=img)\n",
    "        aug_lbl = augmenter(image=lbl)\n",
    "        aug_images.append(aug_img)\n",
    "        aug_labels.append(aug_lbl)\n",
    "    return aug_images, aug_labels\n",
    "\n",
    "# Apply augmentations\n",
    "vflip_images, vflip_labels = augment_data(vflip, gray_images_x_train, y_train)\n",
    "hflip_images, hflip_labels = augment_data(hflip,gray_images_x_train, y_train)\n",
    "tp_images, tp_labels = augment_data(transpose, gray_images_x_train, y_train)\n",
    "ssr_images, ssr_labels = augment_data(shift_scale_rotate, gray_images_x_train, y_train)\n",
    "t90_images, t90_labels = augment_data(rotate90, gray_images_x_train, y_train)\n",
    "t180_images, t180_labels = augment_data(rotate180, gray_images_x_train, y_train)\n",
    "t270_images, t270_labels = augment_data(rotate270, gray_images_x_train, y_train)\n",
    "t360_images, t360_labels = augment_data(rotate360, gray_images_x_train, y_train)\n",
    "\n",
    "# Concatenate the original and augmented data\n",
    "X_train_final = np.array(list(gray_images_x_train) + vflip_images + hflip_images + tp_images + ssr_images + t90_images + t180_images + t270_images + t360_images)\n",
    "y_train_final = np.array(list(y_train) + vflip_labels + hflip_labels + tp_labels + ssr_labels + t90_labels + t180_labels + t270_labels + t360_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aefde490",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_train_final.shape)\n",
    "X_train = X_train_final[..., np.newaxis]\n",
    "print(y_train_final.shape)\n",
    "print(X_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03a1c458",
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from segmentation_models import Unet, Linknet, PSPNet, FPN\n",
    "import segmentation_models as sm\n",
    "from keras.utils import plot_model\n",
    "import numpy as np\n",
    "from numpy import savez_compressed,savez\n",
    "from numpy import load\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix,f1_score,accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17263550",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = (256, 256, 3)\n",
    "model1 = sm.Linknet('resnet34', input_shape=input_shape,weights=None, classes=1, activation='sigmoid')\n",
    "\n",
    "# Define the optimizer\n",
    "opt = keras.optimizers.Adam(learning_rate=0.0001)\n",
    "\n",
    "# Compile the model with the desired loss function and metrics\n",
    "model1.compile(optimizer=opt, loss=sm.losses.bce_jaccard_loss, metrics=[sm.metrics.iou_score])\n",
    "model1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "613933a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_rgb = np.repeat(X_train, 3, axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a34e301e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_train_rgb.shape)\n",
    "print(y_train_final.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90331fa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_checkpoint_callback = ModelCheckpoint(\n",
    "    filepath='Linknetweights.{epoch:02d}-{val_loss:.2f}.h5',\n",
    "    save_weights_only=False,\n",
    "    monitor='val_loss',\n",
    "    mode='min',\n",
    "    save_best_only=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a782307",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the model to your training data\n",
    "model1.fit(\n",
    "    X_train_rgb, y_train_final,\n",
    "    batch_size=16,\n",
    "    epochs=50,\n",
    "    validation_split=0.2,\n",
    "    callbacks=[model_checkpoint_callback]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5a682879",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Unknown layer: Functional",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-3cf73e498761>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[0mmodel_path\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34mr'D:\\Project\\new_Linknetweights.01-1.39.h5'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mload_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcompile\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\miniconda3\\envs\\gpu_env\\lib\\site-packages\\tensorflow_core\\python\\keras\\saving\\save.py\u001b[0m in \u001b[0;36mload_model\u001b[1;34m(filepath, custom_objects, compile)\u001b[0m\n\u001b[0;32m    144\u001b[0m   if (h5py is not None and (\n\u001b[0;32m    145\u001b[0m       isinstance(filepath, h5py.File) or h5py.is_hdf5(filepath))):\n\u001b[1;32m--> 146\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mhdf5_format\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_model_from_hdf5\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcustom_objects\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcompile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    147\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    148\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msix\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstring_types\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\gpu_env\\lib\\site-packages\\tensorflow_core\\python\\keras\\saving\\hdf5_format.py\u001b[0m in \u001b[0;36mload_model_from_hdf5\u001b[1;34m(filepath, custom_objects, compile)\u001b[0m\n\u001b[0;32m    166\u001b[0m     \u001b[0mmodel_config\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloads\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel_config\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'utf-8'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    167\u001b[0m     model = model_config_lib.model_from_config(model_config,\n\u001b[1;32m--> 168\u001b[1;33m                                                custom_objects=custom_objects)\n\u001b[0m\u001b[0;32m    169\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    170\u001b[0m     \u001b[1;31m# set weights\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\gpu_env\\lib\\site-packages\\tensorflow_core\\python\\keras\\saving\\model_config.py\u001b[0m in \u001b[0;36mmodel_from_config\u001b[1;34m(config, custom_objects)\u001b[0m\n\u001b[0;32m     53\u001b[0m                     '`Sequential.from_config(config)`?')\n\u001b[0;32m     54\u001b[0m   \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdeserialize\u001b[0m  \u001b[1;31m# pylint: disable=g-import-not-at-top\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 55\u001b[1;33m   \u001b[1;32mreturn\u001b[0m \u001b[0mdeserialize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcustom_objects\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcustom_objects\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     56\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     57\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\gpu_env\\lib\\site-packages\\tensorflow_core\\python\\keras\\layers\\serialization.py\u001b[0m in \u001b[0;36mdeserialize\u001b[1;34m(config, custom_objects)\u001b[0m\n\u001b[0;32m    104\u001b[0m       \u001b[0mmodule_objects\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mglobs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    105\u001b[0m       \u001b[0mcustom_objects\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcustom_objects\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 106\u001b[1;33m       printable_module_name='layer')\n\u001b[0m",
      "\u001b[1;32m~\\miniconda3\\envs\\gpu_env\\lib\\site-packages\\tensorflow_core\\python\\keras\\utils\\generic_utils.py\u001b[0m in \u001b[0;36mdeserialize_keras_object\u001b[1;34m(identifier, module_objects, custom_objects, printable_module_name)\u001b[0m\n\u001b[0;32m    290\u001b[0m     \u001b[0mconfig\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0midentifier\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    291\u001b[0m     (cls, cls_config) = class_and_config_for_serialized_keras_object(\n\u001b[1;32m--> 292\u001b[1;33m         config, module_objects, custom_objects, printable_module_name)\n\u001b[0m\u001b[0;32m    293\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    294\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'from_config'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\gpu_env\\lib\\site-packages\\tensorflow_core\\python\\keras\\utils\\generic_utils.py\u001b[0m in \u001b[0;36mclass_and_config_for_serialized_keras_object\u001b[1;34m(config, module_objects, custom_objects, printable_module_name)\u001b[0m\n\u001b[0;32m    248\u001b[0m     \u001b[0mcls\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodule_objects\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclass_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    249\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mcls\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 250\u001b[1;33m       \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Unknown '\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mprintable_module_name\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m': '\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mclass_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    251\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    252\u001b[0m   \u001b[0mcls_config\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconfig\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'config'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Unknown layer: Functional"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage.color import rgb2gray\n",
    "from lime import lime_image\n",
    "from skimage.segmentation import mark_boundaries\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "model_path = r'D:\\Project\\new_Linknetweights.01-1.39.h5'\n",
    "model = load_model(model_path, compile=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a39e5dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "\n",
    "model_path = r'D:\\Project\\new_Linknetweights.01-1.39.h5'\n",
    "with h5py.File(model_path, 'r') as f:\n",
    "    print(list(f.keys()))\n",
    "    if 'model_config' in f.attrs:\n",
    "        print(\"Model config found.\")\n",
    "    else:\n",
    "        print(\"Model config not found.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21c2bcd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to preprocess images (if necessary)\n",
    "def preprocess_input(img):\n",
    "    # Convert RGB image to grayscale\n",
    "    gray_img = rgb2gray(img)\n",
    "    # Create fake RGB image by repeating grayscale values across three channels\n",
    "    fake_rgb_img = np.repeat(gray_img[..., np.newaxis], 3, axis=-1)\n",
    "    # Normalize or preprocess your image data as required\n",
    "    return fake_rgb_img / 255.0\n",
    "\n",
    "# Load and preprocess a sample RGB image\n",
    "sample_rgb_image = X_train[0]  # Replace with your RGB image data\n",
    "processed_image = preprocess_input(sample_rgb_image)\n",
    "\n",
    "# Create a LIME image explainer\n",
    "explainer = lime_image.LimeImageExplainer()\n",
    "\n",
    "# Define a function for LIME to use for predictions\n",
    "def predict_fn(images):\n",
    "    # Ensure input matches expected shape (adjust as per your model's requirements)\n",
    "    predictions = model.predict(images[np.newaxis, ...])\n",
    "    # Example: Extract probability map for foreground class (class 1)\n",
    "    return predictions[..., 1]  # Assuming class 1 is foreground\n",
    "\n",
    "# Explain the prediction on the sample image using LIME\n",
    "explanation = explainer.explain_instance(\n",
    "    image=processed_image.astype(np.uint8),  # Ensure image is in correct format for LIME\n",
    "    classifier_fn=predict_fn,\n",
    "    top_labels=1,\n",
    "    hide_color=0,\n",
    "    num_samples=1000  # Number of perturbed samples to generate\n",
    ")\n",
    "\n",
    "# Get the explanation for the top label (adjust as per your model's output)\n",
    "temp, mask = explanation.get_image_and_mask(\n",
    "    label=explanation.top_labels[0],\n",
    "    positive_only=True,\n",
    "    num_features=10,\n",
    "    hide_rest=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b713aae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the result\n",
    "plt.imshow(mark_boundaries(sample_rgb_image.astype(np.uint8), mask))\n",
    "plt.title('LIME Explanation on Fake RGB Image')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eb1339c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (gpu_env)",
   "language": "python",
   "name": "gpu_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
