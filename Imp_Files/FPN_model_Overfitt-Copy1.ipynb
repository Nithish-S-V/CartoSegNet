{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a3af23c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of images: 49, Number of labels: 49\n",
      "Image and label names match: scene1.0.tif and boundary1.0.tif\n",
      "Image and label names match: scene1.1.tif and boundary1.1.tif\n",
      "Image and label names match: scene1.105.tif and boundary1.105.tif\n",
      "Image and label names match: scene1.106.tif and boundary1.106.tif\n",
      "Image and label names match: scene1.107.tif and boundary1.107.tif\n",
      "Image and label names match: scene1.108.tif and boundary1.108.tif\n",
      "Image and label names match: scene1.109.tif and boundary1.109.tif\n",
      "Image and label names match: scene1.110.tif and boundary1.110.tif\n",
      "Image and label names match: scene1.111.tif and boundary1.111.tif\n",
      "Image and label names match: scene1.126.tif and boundary1.126.tif\n",
      "Image and label names match: scene1.127.tif and boundary1.127.tif\n",
      "Image and label names match: scene1.128.tif and boundary1.128.tif\n",
      "Image and label names match: scene1.129.tif and boundary1.129.tif\n",
      "Image and label names match: scene1.130.tif and boundary1.130.tif\n",
      "Image and label names match: scene1.131.tif and boundary1.131.tif\n",
      "Image and label names match: scene1.132.tif and boundary1.132.tif\n",
      "Image and label names match: scene1.2.tif and boundary1.2.tif\n",
      "Image and label names match: scene1.21.tif and boundary1.21.tif\n",
      "Image and label names match: scene1.22.tif and boundary1.22.tif\n",
      "Image and label names match: scene1.23.tif and boundary1.23.tif\n",
      "Image and label names match: scene1.24.tif and boundary1.24.tif\n",
      "Image and label names match: scene1.25.tif and boundary1.25.tif\n",
      "Image and label names match: scene1.26.tif and boundary1.26.tif\n",
      "Image and label names match: scene1.27.tif and boundary1.27.tif\n",
      "Image and label names match: scene1.3.tif and boundary1.3.tif\n",
      "Image and label names match: scene1.4.tif and boundary1.4.tif\n",
      "Image and label names match: scene1.42.tif and boundary1.42.tif\n",
      "Image and label names match: scene1.43.tif and boundary1.43.tif\n",
      "Image and label names match: scene1.44.tif and boundary1.44.tif\n",
      "Image and label names match: scene1.45.tif and boundary1.45.tif\n",
      "Image and label names match: scene1.46.tif and boundary1.46.tif\n",
      "Image and label names match: scene1.47.tif and boundary1.47.tif\n",
      "Image and label names match: scene1.48.tif and boundary1.48.tif\n",
      "Image and label names match: scene1.5.tif and boundary1.5.tif\n",
      "Image and label names match: scene1.6.tif and boundary1.6.tif\n",
      "Image and label names match: scene1.63.tif and boundary1.63.tif\n",
      "Image and label names match: scene1.64.tif and boundary1.64.tif\n",
      "Image and label names match: scene1.65.tif and boundary1.65.tif\n",
      "Image and label names match: scene1.66.tif and boundary1.66.tif\n",
      "Image and label names match: scene1.67.tif and boundary1.67.tif\n",
      "Image and label names match: scene1.68.tif and boundary1.68.tif\n",
      "Image and label names match: scene1.69.tif and boundary1.69.tif\n",
      "Image and label names match: scene1.84.tif and boundary1.84.tif\n",
      "Image and label names match: scene1.85.tif and boundary1.85.tif\n",
      "Image and label names match: scene1.86.tif and boundary1.86.tif\n",
      "Image and label names match: scene1.87.tif and boundary1.87.tif\n",
      "Image and label names match: scene1.88.tif and boundary1.88.tif\n",
      "Image and label names match: scene1.89.tif and boundary1.89.tif\n",
      "Image and label names match: scene1.90.tif and boundary1.90.tif\n",
      "CSV file created\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import glob\n",
    "import os\n",
    "import tensorflow as tf\n",
    "gpus = tf.config.list_physical_devices(\"GPU\")\n",
    "def csv_gen(image_folder, image_format, label_folder, label_format, output_csv):\n",
    "    rows = []\n",
    "    image_paths = sorted(glob.glob(os.path.join(image_folder, f\"*.{image_format}\")))\n",
    "    label_paths = sorted(glob.glob(os.path.join(label_folder, f\"*.{label_format}\")))\n",
    "    print(f\"Number of images: {len(image_paths)}, Number of labels: {len(label_paths)}\")\n",
    "    \n",
    "    for i, j in zip(image_paths, label_paths):\n",
    "        if os.path.splitext(os.path.basename(i))[0] == os.path.splitext(os.path.basename(j))[0]:\n",
    "            rows.append([i, j])\n",
    "        else:\n",
    "            print(f\"Image and label names match: {os.path.basename(i)} and {os.path.basename(j)}\")\n",
    "            rows.append([i, j])\n",
    "\n",
    "    with open(output_csv, 'w', newline='') as csvfile:\n",
    "        csvwriter = csv.writer(csvfile)\n",
    "        csvwriter.writerows(rows)\n",
    "    \n",
    "    print(\"CSV file created\")\n",
    "\n",
    "# Parameters\n",
    "image_folder = \"scene/scene1\"\n",
    "image_format = \"tif\"\n",
    "label_folder = \"boundary/boundary1\"\n",
    "label_format = \"tif\"\n",
    "output_csv = \"output.csv\"\n",
    "\n",
    "# Generate CSV\n",
    "csv_gen(image_folder, image_format, label_folder, label_format, output_csv)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9faf70cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from keras.layers import Input, Conv2D, MaxPooling2D,Activation,concatenate\n",
    "\n",
    "from keras.layers import Dense, Flatten,BatchNormalization,UpSampling2D,Add\n",
    "from keras.models import Model\n",
    "def buildmodel_unet(input_shape, num_classes):\n",
    "    inputs = Input(shape=input_shape)\n",
    "\n",
    "    c1 = Conv2D(64, (1,1), activation='relu', padding='same')(inputs)\n",
    "    c1 = Conv2D(64, (1,1), activation='relu', padding='same')(c1)\n",
    "    p1 = MaxPooling2D((2, 2))(c1)\n",
    "    \n",
    "    c2 = Conv2D(128, (1,1), activation='relu', padding='same')(p1)\n",
    "    c2 = Conv2D(128, (1,1), activation='relu', padding='same')(c2)\n",
    "    p2 = MaxPooling2D((2, 2))(c2)\n",
    "    \n",
    "    c3 = Conv2D(256, (1,1), activation='relu', padding='same')(p2)\n",
    "    c3 = Conv2D(256, (1,1), activation='relu', padding='same')(c3)\n",
    "    c3 = Conv2D(256, (1,1), activation='relu', padding='same')(c3)\n",
    "    p3 = MaxPooling2D((2, 2))(c3)\n",
    "    \n",
    "    c4 = Conv2D(512, (1,1), activation='relu', padding='same')(p3)\n",
    "    c4 = Conv2D(512, (1,1), activation='relu', padding='same')(c4)\n",
    "    c4 = Conv2D(512, (1,1), activation='relu', padding='same')(c4)\n",
    "    p4 = MaxPooling2D((2, 2))(c4)\n",
    "    \n",
    "    # Bottleneck\n",
    "    \n",
    "    c5 = Conv2D(512, (1,1), activation='relu', padding='same')(p4)\n",
    "    c5 = Conv2D(512, (1,1), activation='relu', padding='same')(c5)\n",
    "    c5 = Conv2D(512, (1,1), activation='relu', padding='same')(c5)\n",
    "    \n",
    "    #sepeartion------\n",
    "    \n",
    "    p5 = MaxPooling2D((2, 2))(c5)\n",
    "    \n",
    "    # center_blocks\n",
    "    \n",
    "    cb1 = Conv2D(512, (1,1), padding='same')(p5)\n",
    "    bn1 = BatchNormalization()(cb1)\n",
    "    act1 = Activation('relu')(bn1)\n",
    "    \n",
    "    cb2 = Conv2D(512, (1,1), padding='same')(act1)\n",
    "    bn2 = BatchNormalization()(cb2)\n",
    "    act2 = Activation('relu')(bn2)\n",
    "    \n",
    "    #Decoder_stage\n",
    "    \n",
    "    up1 = UpSampling2D((2, 2))(act2)\n",
    "    \n",
    "    u1 = concatenate([up1, c5])\n",
    "    \n",
    "    c6 = Conv2D(256,(1,1), padding='same')(u1)\n",
    "    bn3 = BatchNormalization()(c6)\n",
    "    act3 = Activation('relu')(bn3)\n",
    "    \n",
    "    c7 = Conv2D(256, (1,1) , padding='same')(act3)\n",
    "    bn4 = BatchNormalization()(c7)\n",
    "    act4 = Activation('relu')(bn4)\n",
    "    \n",
    "    up2 = UpSampling2D((2, 2))(act4)\n",
    "    \n",
    "    u2 = concatenate([up2, c4])\n",
    "    \n",
    "    c8 = Conv2D(128, (1,1) , padding='same')(u2)\n",
    "    bn5 = BatchNormalization()(c8)\n",
    "    act5 = Activation('relu')(bn5)\n",
    "    \n",
    "    c9 = Conv2D(128, (1,1) , padding='same')(act5)\n",
    "    bn6 = BatchNormalization()(c9)\n",
    "    act6 = Activation('relu')(bn6)\n",
    "    \n",
    "    up3 = UpSampling2D((2, 2))(act6)\n",
    "    \n",
    "    u3 = concatenate([up3, c3])\n",
    "    \n",
    "    c10 = Conv2D(64, (1,1), padding='same')(u3)\n",
    "    bn7 = BatchNormalization()(c10)\n",
    "    act7 = Activation('relu')(bn7)\n",
    "    \n",
    "    c11 = Conv2D(64, (1,1), padding='same')(act7)\n",
    "    bn8 = BatchNormalization()(c11)\n",
    "    act8 = Activation('relu')(bn8)\n",
    "    \n",
    "    up4 = UpSampling2D((2, 2))(act8)\n",
    "    \n",
    "    u4 = concatenate([up4, c2])\n",
    "    \n",
    "    c12 = Conv2D(32, (1,1) , padding='same')(u4)\n",
    "    bn9 = BatchNormalization()(c12)\n",
    "    act9 = Activation('relu')(bn9)\n",
    "    \n",
    "    c13 = Conv2D(32, (1,1), padding='same')(act9)\n",
    "    bn10 = BatchNormalization()(c13)\n",
    "    act10 = Activation('relu')(bn10)\n",
    "    \n",
    "    up5 = UpSampling2D((2, 2))(act10)\n",
    "    \n",
    "    c14 = Conv2D(16, (1,1), padding='same')(up5)\n",
    "    bn11 = BatchNormalization()(c14)\n",
    "    act11 = Activation('relu')(bn11)\n",
    "    \n",
    "    c15 = Conv2D(16, (1,1) , padding='same')(act11)\n",
    "    bn12 = BatchNormalization()(c15)\n",
    "    act12 = Activation('relu')(bn12)\n",
    "    \n",
    "    c16 = Conv2D(num_classes,(1,1))(act12)\n",
    "    outputs=Activation('sigmoid')(c16)\n",
    "    \n",
    "    model = Model(inputs, outputs)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7d38798c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fpn_model(input_shape, num_classes):\n",
    "    inputs = Input(shape=input_shape)\n",
    "    #--------block1-----\n",
    "    \n",
    "    c1 = Conv2D(64, (1,1), activation='relu', padding='same')(inputs)\n",
    "    c1 = Conv2D(64, (1,1), activation='relu', padding='same')(c1)\n",
    "    p1 = MaxPooling2D((2, 2))(c1)\n",
    "    \n",
    "    #--------block2---------\n",
    "    \n",
    "    c2 = Conv2D(128, (1,1), activation='relu', padding='same')(p1)\n",
    "    c2 = Conv2D(128, (1,1), activation='relu', padding='same')(c2)\n",
    "    \n",
    "    #------1st-------------\n",
    "    \n",
    "    p2 = MaxPooling2D((2, 2))(c2)\n",
    "    \n",
    "    #--------block3-----------\n",
    "    \n",
    "    c3 = Conv2D(256, (1,1), activation='relu', padding='same')(p2)\n",
    "    c3 = Conv2D(256, (1,1), activation='relu', padding='same')(c3)\n",
    "    c3 = Conv2D(256, (1,1), activation='relu', padding='same')(c3)\n",
    "    \n",
    "    #------2nd----------------\n",
    "    \n",
    "    p3 = MaxPooling2D((2, 2))(c3)\n",
    "    \n",
    "    #----------block4-------\n",
    "    \n",
    "    c4 = Conv2D(512, (1,1), activation='relu', padding='same')(p3)\n",
    "    c4 = Conv2D(512, (1,1), activation='relu', padding='same')(c4)\n",
    "    c4 = Conv2D(512, (1,1), activation='relu', padding='same')(c4)\n",
    "    \n",
    "    #-----------3rd-----------\n",
    "    \n",
    "    p4 = MaxPooling2D((2, 2))(c4)\n",
    "    \n",
    "    #-------------block5------------\n",
    "    \n",
    "    c5 = Conv2D(512, (1,1), activation='relu', padding='same')(p4)\n",
    "    c5 = Conv2D(512, (1,1), activation='relu', padding='same')(c5)\n",
    "    c5 = Conv2D(512, (1,1), activation='relu', padding='same')(c5)\n",
    "\n",
    "    #-----------4th------------\n",
    "    \n",
    "    p5 = MaxPooling2D((2, 2))(c5)\n",
    "    \n",
    "    p5_pre_conv=Conv2D(256,(1,1),activation='relu', padding='same')(p5)\n",
    "    p5_upsampling=UpSampling2D((2, 2))(p5_pre_conv)\n",
    "    \n",
    "    fpn_stage_p5_conv=Conv2D(256,(1,1),activation='relu', padding='same')(c5)\n",
    "    #-----------4th------------END\n",
    "    p5_add= Add()([fpn_stage_p5_conv, p5_upsampling])\n",
    "    \n",
    "    \n",
    "    \n",
    "    #-------------------5---1th------------\n",
    "    \n",
    "    segm_5_a_conv = Conv2D(128, (1,1), padding='same')(p5_add)\n",
    "    seg_5_a_bn1 = BatchNormalization()(segm_5_a_conv)\n",
    "    seg_5_a_act1 = Activation('relu')(seg_5_a_bn1)\n",
    "    \n",
    "    segm_5_b_conv = Conv2D(128, (1,1), padding='same')(seg_5_a_act1)\n",
    "    seg_5_b_bn1 = BatchNormalization()(segm_5_b_conv)\n",
    "    seg_5_b_act1 = Activation('relu')(seg_5_b_bn1)\n",
    "    \n",
    "    #----------------5th---->1th-->END----\n",
    "    \n",
    "    upsampling_stage5= UpSampling2D((8, 8))(seg_5_b_act1)\n",
    "    \n",
    "    #-------------------5th---2nd------------\n",
    "    \n",
    "    p4_upsampling = UpSampling2D((2, 2))(p5_add)\n",
    "    \n",
    "    fpn_stage_p4_conv = Conv2D(256, (1,1), activation='relu', padding='same')(c4)\n",
    "     #---------------3rd------------END\n",
    "    p4_add = Add()([p4_upsampling, fpn_stage_p4_conv])\n",
    "    \n",
    "    #-------------------5th-2nd->1st---------------\n",
    "    \n",
    "    seg_stage4a_conv = Conv2D(128, (1,1), padding='same')(p4_add)\n",
    "    seg_stage4a_bn = BatchNormalization()(seg_stage4a_conv)\n",
    "    seg_stage4a_relu= Activation('relu')(seg_stage4a_bn)\n",
    "    \n",
    "    seg_stage4b_conv = Conv2D(128, (1,1), padding='same')(seg_stage4a_relu)\n",
    "    seg_stage4b_bn = BatchNormalization()(seg_stage4b_conv)\n",
    "    seg_stage4b_relu= Activation('relu')(seg_stage4b_bn)\n",
    "    \n",
    "    #---------------------5th--2nd->1st->end---------------\n",
    "    \n",
    "    upsampling_stage4 = UpSampling2D((4,4))(seg_stage4b_relu)\n",
    "   \n",
    "    #----------5th---2nd->2nd-------------------------\n",
    "    \n",
    "    fpn_stage_p3_upsampling = UpSampling2D((2, 2))(p4_add)\n",
    "    fpn_stage_p3_conv = Conv2D(256, (1,1), activation='relu', padding='same')(c3)\n",
    "    #----------------------2nd-----------end\n",
    "    p3_add =  Add()([fpn_stage_p3_upsampling, fpn_stage_p3_conv])\n",
    "    \n",
    "    \n",
    "    #----------------5th---2nd->2nd--->1st-----------------\n",
    "    \n",
    "    segm_stage3a_conv = Conv2D(128, (1,1), padding='same')(p3_add)\n",
    "    segm_stage3a_bn = BatchNormalization()(segm_stage3a_conv)\n",
    "    segm_stage3a_relu = Activation('relu')(segm_stage3a_bn)\n",
    "    \n",
    "    segm_stage3b_conv = Conv2D(128, (1,1), padding='same')(segm_stage3a_relu)\n",
    "    segm_stage3b_bn = BatchNormalization()(segm_stage3b_conv)\n",
    "    segm_stage3b_relu = Activation('relu')(segm_stage3b_bn)\n",
    "    \n",
    "    #----------------5th---2nd->2nd--->1st-----------END\n",
    "    \n",
    "    upsampling_stage3 = UpSampling2D((2, 2))(segm_stage3b_relu)\n",
    "    \n",
    "    #----------------5th---2nd->2nd--->2nd-----------------\n",
    "    \n",
    "    fpn_stage_p2_upsampling = UpSampling2D((2, 2))(p3_add)\n",
    "    fpn_stage_p2_conv = Conv2D(256, (1,1), activation='relu', padding='same')(c2)\n",
    "    #------------------1st---------------END\n",
    "    p2_add = Add()([fpn_stage_p2_upsampling, fpn_stage_p2_conv])\n",
    "    \n",
    "    segm_stage2a_conv = Conv2D(128, (1,1), padding='same')(p2_add)\n",
    "    segm_stage2a_bn = BatchNormalization()(segm_stage2a_conv)\n",
    "    segm_stage2a_relu = Activation('relu')(segm_stage2a_bn)\n",
    "    \n",
    "    segm_stage2b_conv = Conv2D(128, (1,1), padding='same')(segm_stage2a_relu)\n",
    "    segm_stage2b_bn = BatchNormalization()(segm_stage2b_conv)\n",
    "    #----------------5th---2nd->2nd--->2nd-----------------END\n",
    "    segm_stage2b_relu = Activation('relu')(segm_stage2b_bn)\n",
    "    \n",
    "    #-------------------Final-------------\n",
    "    aggregation_concat = concatenate([upsampling_stage5,upsampling_stage4,upsampling_stage3,segm_stage2b_relu])\n",
    "    \n",
    "    final_stage_conv = Conv2D(128, (1,1), padding='same')(aggregation_concat)\n",
    "    final_stage_bn = BatchNormalization()(final_stage_conv)\n",
    "    final_stage_relu = Activation('relu')(final_stage_bn)\n",
    "    final_upsampling = UpSampling2D((2, 2))(final_stage_relu)\n",
    "    head_conv = Conv2D( num_classes, (1,1), padding='same')(final_upsampling)\n",
    "    outputs=Activation('sigmoid')(head_conv)\n",
    "    \n",
    "    model = Model(inputs,outputs)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8c8e0094",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras.utils import Sequence\n",
    "import gdal\n",
    "import csv\n",
    "import tensorflow as tf\n",
    "\n",
    "class DataGenerator(Sequence):\n",
    "    'Generates data for Keras'\n",
    "    def __init__(self, image_paths, label_paths, batch_size=32, n_classes=2, n_channels=3, patch_size=(128, 128),\n",
    "                 shuffle=True, rs=255, rs_label=1):\n",
    "        'Initialization'\n",
    "        self.batch_size = batch_size\n",
    "        self.label_paths = label_paths\n",
    "        self.image_paths = image_paths\n",
    "        self.n_classes = n_classes\n",
    "        self.n_channels = n_channels\n",
    "        self.patch_size = patch_size\n",
    "        self.shuffle = shuffle\n",
    "        self.rescale_value = rs\n",
    "        self.rs_label = rs_label\n",
    "        self.on_epoch_end()\n",
    "\n",
    "    def __len__(self):\n",
    "        'Denotes the number of batches per epoch'\n",
    "        return int(np.ceil(len(self.image_paths) / self.batch_size))\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        'Generate one batch of data'\n",
    "        indexes = self.indexes[index * self.batch_size:(index + 1) * self.batch_size]\n",
    "        list_image_temp = [self.image_paths[k] for k in indexes]\n",
    "        list_label_temp = [self.label_paths[k] for k in indexes]\n",
    "        X, y = self.__data_generation(list_image_temp, list_label_temp)\n",
    "        return X, y\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        'Updates indexes after each epoch'\n",
    "        self.indexes = np.arange(len(self.image_paths))\n",
    "        if self.shuffle:\n",
    "            np.random.shuffle(self.indexes)\n",
    "\n",
    "    def __data_generation(self, image_paths, label_paths):\n",
    "        'Generates data containing batch_size samples'\n",
    "        X = np.empty((self.batch_size, *self.patch_size, self.n_channels))\n",
    "        y = np.empty((self.batch_size, *self.patch_size, 1), dtype=int)\n",
    "        for i, (image, label) in enumerate(zip(image_paths, label_paths)):\n",
    "            _image = gdal.Open(image)\n",
    "            _label = gdal.Open(label)\n",
    "            if _image is None or _label is None:\n",
    "                print(f\"Failed to open image or label file: {image}, {label}\")\n",
    "                continue\n",
    "            _image = np.array(_image.ReadAsArray()) / self.rescale_value\n",
    "            _image = _image.transpose(1, 2, 0)\n",
    "            _label = np.array(_label.ReadAsArray()) / self.rs_label\n",
    "            _label = np.expand_dims(_label, axis=-1)\n",
    "            X[i,] = _image\n",
    "            y[i,] = _label\n",
    "        return X, y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c285bb84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# from keras.callbacks import ModelCheckpoint, CSVLogger\n",
    "# import datetime\n",
    "# import csv\n",
    "# from sklearn.metrics import confusion_matrix, accuracy_score , f1_score\n",
    "# def read_csv(csv_file):\n",
    "#     image_paths = []\n",
    "#     label_paths = []\n",
    "#     with open(csv_file, 'r') as file:\n",
    "#         reader = csv.reader(file)\n",
    "#         for row in reader:\n",
    "#             image_paths.append(row[0])\n",
    "#             label_paths.append(row[1])\n",
    "#     return image_paths, label_paths\n",
    "\n",
    "# # Example usage:\n",
    "# csv_file = \"output.csv\"\n",
    "# image_paths, label_paths = read_csv(csv_file)\n",
    "\n",
    "# # Train, Validation and Test Split\n",
    "# train_val_split_index = int(len(image_paths) * 0.8)\n",
    "# train_image_paths = image_paths[:train_val_split_index]\n",
    "# train_label_paths = label_paths[:train_val_split_index]\n",
    "# valid_test_image_paths = image_paths[train_val_split_index:]\n",
    "# valid_test_label_paths = label_paths[train_val_split_index:]\n",
    "\n",
    "# valid_split_index = int(len(valid_test_image_paths) * 0.5)\n",
    "# valid_image_paths = valid_test_image_paths[:valid_split_index]\n",
    "# valid_label_paths = valid_test_label_paths[:valid_split_index]\n",
    "# test_image_paths = valid_test_image_paths[valid_split_index:]\n",
    "# test_label_paths = valid_test_label_paths[valid_split_index:]\n",
    "\n",
    "# def train(model_name, train_image_paths, train_label_paths, valid_image_paths, valid_label_paths, \n",
    "#           input_shape, batch_size, num_classes, epochs, rs, rs_label, weights=None):\n",
    "#     rescale_value = 2 ** rs - 1\n",
    "    \n",
    "#     # Building the model\n",
    "#     model = buildmodel_unet(input_shape, num_classes)\n",
    "    \n",
    "#     if weights:\n",
    "#         model.load_weights(weights)\n",
    "    \n",
    "#     if num_classes > 1:\n",
    "#         loss_fun = \"categorical_crossentropy\"\n",
    "#     elif num_classes == 1:\n",
    "#         loss_fun = \"binary_crossentropy\"\n",
    "#     else:\n",
    "#         raise ValueError(\"Number of classes not specified correctly\")\n",
    "    \n",
    "#     model.compile(optimizer=\"adam\", loss=loss_fun, metrics=[\"acc\"])\n",
    "    \n",
    "#     # Custom data generator\n",
    "#     train_gen = DataGenerator(\n",
    "#         train_image_paths, \n",
    "#         train_label_paths,\n",
    "#         batch_size=batch_size,\n",
    "#         patch_size=(256, 256),\n",
    "#         n_channels=3,\n",
    "#         n_classes=num_classes,\n",
    "#         rs=rs,\n",
    "#         rs_label=rs_label,\n",
    "#         shuffle=True\n",
    "#     )\n",
    "    \n",
    "#     valid_gen = DataGenerator(\n",
    "#         valid_image_paths, \n",
    "#         valid_label_paths,\n",
    "#         batch_size=batch_size,\n",
    "#         patch_size=(256, 256),\n",
    "#         n_channels=3,\n",
    "#         n_classes=num_classes,\n",
    "#         rs=rs,\n",
    "#         rs_label=rs_label,\n",
    "#         shuffle=False\n",
    "#     )\n",
    "    \n",
    "#     train_steps = len(train_image_paths) // batch_size\n",
    "#     valid_steps = len(valid_image_paths) // batch_size\n",
    "    \n",
    "#     model_checkpoint = ModelCheckpoint(filepath='best_model.h5', save_best_only=True, monitor='val_loss', mode='min')\n",
    "#     csv_logger = CSVLogger('training_log.csv')\n",
    "    \n",
    "#     model.fit(\n",
    "#         train_gen,\n",
    "#         steps_per_epoch=train_steps,\n",
    "#         validation_data=valid_gen,\n",
    "#         validation_steps=valid_steps,\n",
    "#         epochs=epochs,\n",
    "#         callbacks=[model_checkpoint]\n",
    "#     )\n",
    "    \n",
    "    \n",
    "#     print(\"Model successfully trained\")\n",
    "\n",
    "#     return model\n",
    "\n",
    "# def evaluate_model(model, test_image_paths, test_label_paths, batch_size, rs, rs_label):\n",
    "#     test_gen = DataGenerator(\n",
    "#         test_image_paths, \n",
    "#         test_label_paths,\n",
    "#         batch_size=batch_size,\n",
    "#         patch_size=(256, 256),\n",
    "#         n_channels=3,\n",
    "#         n_classes=1,\n",
    "#         rs=rs,\n",
    "#         rs_label=rs_label,\n",
    "#         shuffle=False\n",
    "#     )\n",
    "\n",
    "#     # Get predictions from the model\n",
    "#     predictions = model.predict(test_gen, verbose=1)\n",
    "\n",
    "#     # Flatten predictions and true labels\n",
    "#     pred_masks = (predictions > 0.5).astype(np.uint8).flatten()\n",
    "#     true_masks = np.concatenate([test_gen[i][1].flatten() for i in range(len(test_gen))]).astype(np.uint8)\n",
    "\n",
    "#     # Calculate confusion matrix\n",
    "#     cm = confusion_matrix(true_masks, pred_masks)\n",
    "\n",
    "#     # Check if confusion matrix is binary\n",
    "#     if cm.shape == (2, 2):\n",
    "#         tn, fp, fn, tp = cm.ravel()\n",
    "#     else:\n",
    "#         raise ValueError(\"Confusion matrix does not have the shape (2, 2). This is expected for binary classification.\")\n",
    "\n",
    "#     # Calculate accuracy\n",
    "#     accuracy = accuracy_score(true_masks, pred_masks)\n",
    "\n",
    "#     # Calculate precision, recall, and F1-score\n",
    "#     precision = precision_score(true_masks, pred_masks)\n",
    "#     recall = recall_score(true_masks, pred_masks)\n",
    "#     f1 = f1_score(true_masks, pred_masks)\n",
    "\n",
    "#     # Calculate mean intersection over union (mIoU)\n",
    "#     intersection = np.logical_and(true_masks, pred_masks)\n",
    "#     union = np.logical_or(true_masks, pred_masks)\n",
    "#     iou = np.sum(intersection) / np.sum(union)\n",
    "\n",
    "#     print(\"Evaluation Metrics:\")\n",
    "#     print(f\"Accuracy: {accuracy}\")\n",
    "#     print(f\"Precision: {precision}\")\n",
    "#     print(f\"Recall: {recall}\")\n",
    "#     print(f\"F1-score: {f1}\")\n",
    "#     print(f\"Mean Intersection over Union (mIoU): {iou}\")\n",
    "\n",
    "# # Parameters\n",
    "# model_name = \"unet\"\n",
    "# input_shape = (256, 256, 3)\n",
    "# batch_size = 64\n",
    "# num_classes = 1\n",
    "# epochs = 10\n",
    "# rs = 255\n",
    "# rs_label = 1\n",
    "# weights = None\n",
    "\n",
    "# # Train the model\n",
    "# model = train(model_name, train_image_paths, train_label_paths, valid_image_paths, valid_label_paths, \n",
    "#               input_shape, batch_size, num_classes, epochs, rs, rs_label, weights)\n",
    "\n",
    "# # Evaluate the model\n",
    "# evaluate_model(model, test_image_paths, test_label_paths, batch_size, rs, rs_label)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a92a5056",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "8/8 [==============================] - 17s 2s/step - loss: -2741.5427 - accuracy: 0.1583 - val_loss: 259.6722 - val_accuracy: 0.2026\n",
      "Epoch 2/50\n",
      "8/8 [==============================] - 16s 2s/step - loss: -11289.2461 - accuracy: 0.0547 - val_loss: 1885.5404 - val_accuracy: 0.2026\n",
      "Epoch 3/50\n",
      "8/8 [==============================] - 18s 2s/step - loss: -16765.9863 - accuracy: 0.0801 - val_loss: -651.2761 - val_accuracy: 0.0073\n",
      "Epoch 4/50\n",
      "8/8 [==============================] - 17s 2s/step - loss: -20796.9395 - accuracy: 0.0750 - val_loss: -2007.1426 - val_accuracy: 0.0145\n",
      "Epoch 5/50\n",
      "8/8 [==============================] - 17s 2s/step - loss: -25039.8496 - accuracy: 0.0726 - val_loss: -6957.1650 - val_accuracy: 8.3923e-05\n",
      "Epoch 6/50\n",
      "8/8 [==============================] - 16s 2s/step - loss: -29975.5137 - accuracy: 0.0677 - val_loss: -8841.5430 - val_accuracy: 0.0000e+00\n",
      "Epoch 7/50\n",
      "8/8 [==============================] - 17s 2s/step - loss: -37241.8945 - accuracy: 0.0031 - val_loss: -9502.6084 - val_accuracy: 0.0000e+00\n",
      "Epoch 8/50\n",
      "8/8 [==============================] - 17s 2s/step - loss: -38233.6953 - accuracy: 0.0644 - val_loss: -13801.5449 - val_accuracy: 0.0000e+00\n",
      "Epoch 9/50\n",
      "8/8 [==============================] - 17s 2s/step - loss: -43392.2852 - accuracy: 0.0639 - val_loss: -14783.3203 - val_accuracy: 0.0000e+00\n",
      "Epoch 10/50\n",
      "8/8 [==============================] - 16s 2s/step - loss: -48601.3828 - accuracy: 0.0636 - val_loss: -18224.3047 - val_accuracy: 0.0000e+00\n",
      "Epoch 11/50\n",
      "8/8 [==============================] - 17s 2s/step - loss: -51932.5859 - accuracy: 0.0634 - val_loss: -24256.6660 - val_accuracy: 0.0000e+00\n",
      "Epoch 12/50\n",
      "8/8 [==============================] - 17s 2s/step - loss: -56329.9258 - accuracy: 0.0636 - val_loss: -22650.3301 - val_accuracy: 0.0000e+00\n",
      "Epoch 13/50\n",
      "8/8 [==============================] - 17s 2s/step - loss: -61677.9180 - accuracy: 0.0631 - val_loss: -31418.9609 - val_accuracy: 0.0000e+00\n",
      "Epoch 14/50\n",
      "8/8 [==============================] - 16s 2s/step - loss: -67022.3047 - accuracy: 0.0628 - val_loss: -30090.0469 - val_accuracy: 0.0000e+00\n",
      "Epoch 15/50\n",
      "8/8 [==============================] - 16s 2s/step - loss: -76880.5391 - accuracy: 0.0010 - val_loss: -40303.1797 - val_accuracy: 0.0000e+00\n",
      "Epoch 16/50\n",
      "8/8 [==============================] - 17s 2s/step - loss: -78416.8203 - accuracy: 0.0630 - val_loss: -40212.9492 - val_accuracy: 0.0000e+00\n",
      "Epoch 17/50\n",
      "8/8 [==============================] - 17s 2s/step - loss: -83045.7344 - accuracy: 0.0651 - val_loss: -42963.4609 - val_accuracy: 0.0000e+00\n",
      "Epoch 18/50\n",
      "8/8 [==============================] - 17s 2s/step - loss: -90478.8516 - accuracy: 0.0634 - val_loss: -69639.3281 - val_accuracy: 0.0000e+00\n",
      "Epoch 19/50\n",
      "8/8 [==============================] - 16s 2s/step - loss: -96918.8984 - accuracy: 0.0634 - val_loss: -75074.0156 - val_accuracy: 0.0000e+00\n",
      "Epoch 20/50\n",
      "8/8 [==============================] - 17s 2s/step - loss: -106578.5000 - accuracy: 0.0628 - val_loss: -44896.7109 - val_accuracy: 0.0000e+00\n",
      "Epoch 21/50\n",
      "8/8 [==============================] - 17s 2s/step - loss: -115419.6406 - accuracy: 3.9196e-04 - val_loss: -62341.0156 - val_accuracy: 0.0000e+00\n",
      "Epoch 22/50\n",
      "8/8 [==============================] - 17s 2s/step - loss: -115459.0703 - accuracy: 0.0625 - val_loss: -47920.4375 - val_accuracy: 0.0000e+00\n",
      "Epoch 23/50\n",
      "8/8 [==============================] - 17s 2s/step - loss: -123957.7969 - accuracy: 0.0627 - val_loss: -21592.5898 - val_accuracy: 0.0000e+00\n",
      "Epoch 24/50\n",
      "8/8 [==============================] - 17s 2s/step - loss: -131754.6250 - accuracy: 0.0635 - val_loss: -83244.8984 - val_accuracy: 0.0000e+00\n",
      "Epoch 25/50\n",
      "8/8 [==============================] - 17s 2s/step - loss: -139769.0469 - accuracy: 0.0625 - val_loss: -22870.7930 - val_accuracy: 0.0000e+00\n",
      "Epoch 26/50\n",
      "8/8 [==============================] - 16s 2s/step - loss: -154987.6250 - accuracy: 0.0625 - val_loss: -59978.4648 - val_accuracy: 0.0000e+00\n",
      "Epoch 27/50\n",
      "8/8 [==============================] - 17s 2s/step - loss: -165491.0000 - accuracy: 0.0646 - val_loss: -3641.7207 - val_accuracy: 0.0000e+00\n",
      "Epoch 28/50\n",
      "8/8 [==============================] - 19s 2s/step - loss: -178256.2656 - accuracy: 0.0627 - val_loss: -99647.5469 - val_accuracy: 0.0000e+00\n",
      "Epoch 29/50\n",
      "8/8 [==============================] - 18s 2s/step - loss: -192121.3438 - accuracy: 0.0053 - val_loss: -46217.2344 - val_accuracy: 0.0000e+00\n",
      "Epoch 30/50\n",
      "8/8 [==============================] - 16s 2s/step - loss: -202268.7031 - accuracy: 0.0625 - val_loss: -28340.1074 - val_accuracy: 0.0000e+00\n",
      "Epoch 31/50\n",
      "8/8 [==============================] - 17s 2s/step - loss: -219424.3281 - accuracy: 0.0625 - val_loss: -64119.6328 - val_accuracy: 0.0000e+00\n",
      "Epoch 32/50\n",
      "8/8 [==============================] - 17s 2s/step - loss: -229790.4531 - accuracy: 0.0625 - val_loss: -7034.0396 - val_accuracy: 0.0000e+00\n",
      "Epoch 33/50\n",
      "8/8 [==============================] - 17s 2s/step - loss: -246879.1250 - accuracy: 0.0625 - val_loss: -50886.4414 - val_accuracy: 0.0000e+00\n",
      "Epoch 34/50\n",
      "8/8 [==============================] - 17s 2s/step - loss: -260237.8594 - accuracy: 0.0625 - val_loss: -13628.4648 - val_accuracy: 0.0000e+00\n",
      "Epoch 35/50\n",
      "8/8 [==============================] - 16s 2s/step - loss: -273439.2188 - accuracy: 0.0625 - val_loss: -10243.0137 - val_accuracy: 0.0000e+00\n",
      "Epoch 36/50\n",
      "8/8 [==============================] - 17s 2s/step - loss: -287872.7500 - accuracy: 0.0625 - val_loss: -117765.4922 - val_accuracy: 0.0000e+00\n",
      "Epoch 37/50\n",
      "8/8 [==============================] - 17s 2s/step - loss: -304601.1250 - accuracy: 0.0625 - val_loss: -7656.1699 - val_accuracy: 0.0000e+00\n",
      "Epoch 38/50\n",
      "8/8 [==============================] - 17s 2s/step - loss: -319217.0312 - accuracy: 0.0625 - val_loss: -17125.9668 - val_accuracy: 0.0000e+00\n",
      "Epoch 39/50\n",
      "8/8 [==============================] - 17s 2s/step - loss: -336037.4375 - accuracy: 0.0625 - val_loss: -17019.5742 - val_accuracy: 0.0000e+00\n",
      "Epoch 40/50\n",
      "8/8 [==============================] - 16s 2s/step - loss: -352991.0625 - accuracy: 0.0625 - val_loss: -753514.6875 - val_accuracy: 0.0000e+00\n",
      "Epoch 41/50\n",
      "8/8 [==============================] - 17s 2s/step - loss: -367077.0938 - accuracy: 0.0625 - val_loss: -1477104.5000 - val_accuracy: 0.0000e+00\n",
      "Epoch 42/50\n",
      "8/8 [==============================] - 17s 2s/step - loss: -384347.5625 - accuracy: 0.0625 - val_loss: -1086742.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 43/50\n",
      "8/8 [==============================] - 17s 2s/step - loss: -400654.2500 - accuracy: 0.0625 - val_loss: -483589.0938 - val_accuracy: 0.0000e+00\n",
      "Epoch 44/50\n",
      "8/8 [==============================] - 17s 2s/step - loss: -421784.3750 - accuracy: 0.0625 - val_loss: -23911.8594 - val_accuracy: 0.0000e+00\n",
      "Epoch 45/50\n",
      "8/8 [==============================] - 17s 2s/step - loss: -439666.2500 - accuracy: 0.0625 - val_loss: -10815.4043 - val_accuracy: 0.0000e+00\n",
      "Epoch 46/50\n",
      "8/8 [==============================] - 17s 2s/step - loss: -458247.2500 - accuracy: 0.0625 - val_loss: -48200.3047 - val_accuracy: 0.0000e+00\n",
      "Epoch 47/50\n",
      "8/8 [==============================] - 17s 2s/step - loss: -476546.9688 - accuracy: 0.0625 - val_loss: -62470.9375 - val_accuracy: 0.0000e+00\n",
      "Epoch 48/50\n",
      "8/8 [==============================] - 17s 2s/step - loss: -495476.9062 - accuracy: 0.0625 - val_loss: -69078.8359 - val_accuracy: 0.0000e+00\n",
      "Epoch 49/50\n",
      "8/8 [==============================] - 17s 2s/step - loss: -516836.8125 - accuracy: 0.0625 - val_loss: -667949.3750 - val_accuracy: 0.0000e+00\n",
      "Epoch 50/50\n",
      "8/8 [==============================] - 17s 2s/step - loss: -536697.5000 - accuracy: 0.0625 - val_loss: -254402.4219 - val_accuracy: 0.0000e+00\n",
      "Model successfully trained\n",
      "2/2 [==============================] - 0s 234ms/step\n",
      "Evaluation Metrics:\n",
      "Accuracy: 0.0\n",
      "F1-score: 0.0\n",
      "Mean Intersection over Union (mIoU): 0.0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import csv\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "import tensorflow as tf\n",
    "\n",
    "def read_csv(csv_file):\n",
    "    image_paths = []\n",
    "    label_paths = []\n",
    "    with open(csv_file, 'r') as file:\n",
    "        reader = csv.reader(file)\n",
    "        for row in reader:\n",
    "            image_paths.append(row[0])\n",
    "            label_paths.append(row[1])\n",
    "    return image_paths, label_paths\n",
    "\n",
    "# Example usage:\n",
    "csv_file = \"output.csv\"\n",
    "image_paths, label_paths = read_csv(csv_file)\n",
    "\n",
    "# Train, Validation, and Test Split\n",
    "train_split_index = int(len(image_paths) * 0.7)\n",
    "valid_split_index = int(len(image_paths) * 0.85)\n",
    "\n",
    "train_image_paths = image_paths[:train_split_index]\n",
    "train_label_paths = label_paths[:train_split_index]\n",
    "valid_image_paths = image_paths[train_split_index:valid_split_index]\n",
    "valid_label_paths = label_paths[train_split_index:valid_split_index]\n",
    "test_image_paths = image_paths[valid_split_index:]\n",
    "test_label_paths = label_paths[valid_split_index:]\n",
    "\n",
    "def train(model_name, train_image_paths, train_label_paths, valid_image_paths, valid_label_paths, \n",
    "          input_shape, batch_size, num_classes, epochs, rs, rs_label, weights=None):\n",
    "    rescale_value = 2 ** rs - 1\n",
    "    \n",
    "    # Building the model\n",
    "    model = fpn_model(input_shape, num_classes)\n",
    "    \n",
    "    if weights:\n",
    "        model.load_weights(weights)\n",
    "    \n",
    "    if num_classes > 1:\n",
    "        loss_fun = \"categorical_crossentropy\"\n",
    "    elif num_classes == 1:\n",
    "        loss_fun = \"binary_crossentropy\"\n",
    "    else:\n",
    "        raise ValueError(\"Number of classes not specified correctly\")\n",
    "    \n",
    "    model.compile(optimizer=\"adam\", loss=loss_fun, metrics=[\"accuracy\"])\n",
    "    \n",
    "    # Custom data generator\n",
    "    train_gen = DataGenerator(\n",
    "        train_image_paths, \n",
    "        train_label_paths,\n",
    "        batch_size=batch_size,\n",
    "        patch_size=(256, 256),\n",
    "        n_channels=3,\n",
    "        n_classes=num_classes,\n",
    "        rs=rs,\n",
    "        rs_label=rs_label,\n",
    "        shuffle=True\n",
    "    )\n",
    "    \n",
    "    valid_gen = DataGenerator(\n",
    "        valid_image_paths, \n",
    "        valid_label_paths,\n",
    "        batch_size=batch_size,\n",
    "        patch_size=(256, 256),\n",
    "        n_channels=3,\n",
    "        n_classes=num_classes,\n",
    "        rs=rs,\n",
    "        rs_label=rs_label,\n",
    "        shuffle=False\n",
    "    )\n",
    "    \n",
    "    train_steps = len(train_image_paths) // batch_size\n",
    "    valid_steps = len(valid_image_paths) // batch_size\n",
    "    \n",
    "    # Training the model\n",
    "    model.fit(\n",
    "        train_gen,\n",
    "        steps_per_epoch=train_steps,\n",
    "        validation_data=valid_gen,\n",
    "        validation_steps=valid_steps,\n",
    "        epochs=epochs\n",
    "    )\n",
    "    \n",
    "    print(\"Model successfully trained\")\n",
    "\n",
    "    return model\n",
    "\n",
    "def evaluate_model(model, test_image_paths, test_label_paths, batch_size, rs, rs_label):\n",
    "    test_gen = DataGenerator(\n",
    "        test_image_paths, \n",
    "        test_label_paths,\n",
    "        batch_size=batch_size,\n",
    "        patch_size=(256, 256),\n",
    "        n_channels=3,\n",
    "        n_classes=1,\n",
    "        rs=rs,\n",
    "        rs_label=rs_label,\n",
    "        shuffle=False\n",
    "    )\n",
    "\n",
    "    # Get predictions from the model\n",
    "    predictions = model.predict(test_gen, verbose=1)\n",
    "\n",
    "    # Flatten predictions and true labels\n",
    "    pred_masks = (predictions > 0.5).astype(np.uint8).flatten()\n",
    "    true_masks = np.concatenate([test_gen[i][1].flatten() for i in range(len(test_gen))]).astype(np.uint8)\n",
    "\n",
    "    pred_masks = np.clip(pred_masks, 0, 1)\n",
    "    true_masks = np.clip(true_masks, 0, 1)\n",
    "\n",
    "    # Calculate accuracy\n",
    "    accuracy = accuracy_score(true_masks, pred_masks)\n",
    "\n",
    "    # Calculate F1-score\n",
    "    f1 = f1_score(true_masks, pred_masks, average='binary')\n",
    "\n",
    "    # Calculate mean intersection over union (mIoU)\n",
    "    intersection = np.logical_and(true_masks, pred_masks)\n",
    "    union = np.logical_or(true_masks, pred_masks)\n",
    "    iou = np.sum(intersection) / np.sum(union)\n",
    "\n",
    "    print(\"Evaluation Metrics:\")\n",
    "    print(f\"Accuracy: {accuracy}\")\n",
    "    print(f\"F1-score: {f1}\")\n",
    "    print(f\"Mean Intersection over Union (mIoU): {iou}\")\n",
    "\n",
    "# Parameters\n",
    "model_name = \"unet\"\n",
    "input_shape = (256, 256, 3)\n",
    "batch_size = 4\n",
    "num_classes = 1\n",
    "epochs = 10\n",
    "rs = 255\n",
    "rs_label = 1\n",
    "weights = None\n",
    "\n",
    "# Train the model\n",
    "model = train(model_name, train_image_paths, train_label_paths, valid_image_paths, valid_label_paths, \n",
    "              input_shape, batch_size, num_classes, epochs, rs, rs_label, weights)\n",
    "\n",
    "# Evaluate the model\n",
    "evaluate_model(model, test_image_paths, test_label_paths, batch_size, rs, rs_label)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6b670d1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "2/2 [==============================] - 9s 5s/step - loss: 1469.9866 - accuracy: 0.0734\n",
      "Epoch 2/10\n",
      "2/2 [==============================] - 9s 5s/step - loss: -1481.5182 - accuracy: 0.0595\n",
      "Epoch 3/10\n",
      "2/2 [==============================] - 9s 5s/step - loss: -5454.3447 - accuracy: 0.0643\n",
      "Epoch 4/10\n",
      "2/2 [==============================] - 10s 5s/step - loss: -7585.3638 - accuracy: 0.0649\n",
      "Epoch 5/10\n",
      "2/2 [==============================] - 9s 5s/step - loss: -5162.6494 - accuracy: 0.1117\n",
      "Epoch 6/10\n",
      "2/2 [==============================] - 9s 5s/step - loss: -11164.2441 - accuracy: 0.0520\n",
      "Epoch 7/10\n",
      "2/2 [==============================] - 10s 5s/step - loss: -12915.0615 - accuracy: 0.0541\n",
      "Epoch 8/10\n",
      "2/2 [==============================] - 9s 5s/step - loss: -10725.3145 - accuracy: 0.1032\n",
      "Epoch 9/10\n",
      "2/2 [==============================] - 9s 5s/step - loss: -15015.9492 - accuracy: 0.0508\n",
      "Epoch 10/10\n",
      "2/2 [==============================] - 9s 5s/step - loss: -16081.4902 - accuracy: 0.0423\n",
      "Model successfully trained\n",
      "1/1 [==============================] - 0s 2ms/step\n",
      "Evaluation Metrics:\n",
      "Accuracy: 0.5\n",
      "F1-score: 0.0\n",
      "Mean Intersection over Union (mIoU): 0.0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import csv\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "import tensorflow as tf\n",
    "\n",
    "def read_csv(csv_file):\n",
    "    image_paths = []\n",
    "    label_paths = []\n",
    "    with open(csv_file, 'r') as file:\n",
    "        reader = csv.reader(file)\n",
    "        for row in reader:\n",
    "            image_paths.append(row[0])\n",
    "            label_paths.append(row[1])\n",
    "    return image_paths, label_paths\n",
    "\n",
    "# Example usage:\n",
    "csv_file = \"output.csv\"\n",
    "image_paths, label_paths = read_csv(csv_file)\n",
    "\n",
    "# Train, Validation, and Test Split\n",
    "train_split_index = int(len(image_paths) * 0.7)\n",
    "valid_split_index = int(len(image_paths) * 0.85)\n",
    "\n",
    "train_image_paths = image_paths[:train_split_index]\n",
    "train_label_paths = label_paths[:train_split_index]\n",
    "valid_image_paths = image_paths[train_split_index:valid_split_index]\n",
    "valid_label_paths = label_paths[train_split_index:valid_split_index]\n",
    "test_image_paths = image_paths[valid_split_index:]\n",
    "test_label_paths = label_paths[valid_split_index:]\n",
    "\n",
    "def train(model_name, train_image_paths, train_label_paths, valid_image_paths, valid_label_paths, \n",
    "          input_shape, batch_size, num_classes, epochs, rs, rs_label, weights=None):\n",
    "    rescale_value = 2 ** rs - 1\n",
    "    \n",
    "    # Building the model\n",
    "    model = fpn_model(input_shape, num_classes)\n",
    "    \n",
    "    if weights:\n",
    "        model.load_weights(weights)\n",
    "    \n",
    "    if num_classes > 1:\n",
    "        loss_fun = \"categorical_crossentropy\"\n",
    "    elif num_classes == 1:\n",
    "        loss_fun = \"binary_crossentropy\"\n",
    "    else:\n",
    "        raise ValueError(\"Number of classes not specified correctly\")\n",
    "    \n",
    "    model.compile(optimizer=\"adam\", loss=loss_fun, metrics=[\"accuracy\"])\n",
    "    \n",
    "    # Custom data generator\n",
    "    train_gen = DataGenerator(\n",
    "        train_image_paths, \n",
    "        train_label_paths,\n",
    "        batch_size=batch_size,\n",
    "        patch_size=(256, 256),\n",
    "        n_channels=3,\n",
    "        n_classes=num_classes,\n",
    "        rs=rs,\n",
    "        rs_label=rs_label,\n",
    "        shuffle=True\n",
    "    )\n",
    "    \n",
    "    valid_gen = DataGenerator(\n",
    "        valid_image_paths, \n",
    "        valid_label_paths,\n",
    "        batch_size=batch_size,\n",
    "        patch_size=(256, 256),\n",
    "        n_channels=3,\n",
    "        n_classes=num_classes,\n",
    "        rs=rs,\n",
    "        rs_label=rs_label,\n",
    "        shuffle=False\n",
    "    )\n",
    "    \n",
    "    train_steps = len(train_image_paths) // batch_size\n",
    "    valid_steps = len(valid_image_paths) // batch_size\n",
    "    \n",
    "    # Training the model\n",
    "    model.fit(\n",
    "        train_gen,\n",
    "        steps_per_epoch=train_steps,\n",
    "        validation_data=valid_gen,\n",
    "        validation_steps=valid_steps,\n",
    "        epochs=epochs\n",
    "    )\n",
    "    \n",
    "    print(\"Model successfully trained\")\n",
    "\n",
    "    return model\n",
    "\n",
    "def evaluate_model(model, test_image_paths, test_label_paths, batch_size, rs, rs_label):\n",
    "    test_gen = DataGenerator(\n",
    "        test_image_paths, \n",
    "        test_label_paths,\n",
    "        batch_size=batch_size,\n",
    "        patch_size=(256, 256),\n",
    "        n_channels=3,\n",
    "        n_classes=1,\n",
    "        rs=rs,\n",
    "        rs_label=rs_label,\n",
    "        shuffle=False\n",
    "    )\n",
    "\n",
    "    # Get predictions from the model\n",
    "    predictions = model.predict(test_gen, verbose=1)\n",
    "\n",
    "    # Flatten predictions and true labels\n",
    "    pred_masks = (predictions > 0.5).astype(np.uint8).flatten()\n",
    "    true_masks = np.concatenate([test_gen[i][1].flatten() for i in range(len(test_gen))]).astype(np.uint8)\n",
    "\n",
    "    pred_masks = np.clip(pred_masks, 0, 1)\n",
    "    true_masks = np.clip(true_masks, 0, 1)\n",
    "\n",
    "    # Calculate accuracy\n",
    "    accuracy = accuracy_score(true_masks, pred_masks)\n",
    "\n",
    "    # Calculate F1-score\n",
    "    f1 = f1_score(true_masks, pred_masks, average='binary')\n",
    "\n",
    "    # Calculate mean intersection over union (mIoU)\n",
    "    intersection = np.logical_and(true_masks, pred_masks)\n",
    "    union = np.logical_or(true_masks, pred_masks)\n",
    "    iou = np.sum(intersection) / np.sum(union)\n",
    "\n",
    "    print(\"Evaluation Metrics:\")\n",
    "    print(f\"Accuracy: {accuracy}\")\n",
    "    print(f\"F1-score: {f1}\")\n",
    "    print(f\"Mean Intersection over Union (mIoU): {iou}\")\n",
    "\n",
    "# Parameters\n",
    "model_name = \"unet\"\n",
    "input_shape = (256, 256, 3)\n",
    "batch_size = 16\n",
    "num_classes = 1  # Binary segmentation\n",
    "epochs = 10\n",
    "rs = 8\n",
    "rs_label = 1\n",
    "weights = None\n",
    "\n",
    "# Train the model\n",
    "model = train(model_name, train_image_paths, train_label_paths, valid_image_paths, valid_label_paths, \n",
    "              input_shape, batch_size, num_classes, epochs, rs, rs_label, weights)\n",
    "\n",
    "# Evaluate the model\n",
    "evaluate_model(model, test_image_paths, test_label_paths, batch_size, rs, rs_label)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b0a0fc6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
